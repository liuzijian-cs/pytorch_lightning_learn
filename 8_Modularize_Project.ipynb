{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LIGHTNING DATAMODULE\n",
    "\n",
    "A datamodule is a shareable, reusable class that encapsulates all the steps needed to process data:\n",
    "\n",
    "A datamodule encapsulates the five steps involved in data processing in PyTorch:\n",
    "1. Download / tokenize / process.\n",
    "2. Clean and (maybe) save to disk.\n",
    "3. Load inside Dataset.\n",
    "4. Apply transforms (rotate, tokenize, etc…).\n",
    "5. Wrap inside a DataLoader.\n",
    "\n",
    "# Why do I need a DataModule?\n",
    "\n",
    "在普通的 PyTorch 代码中，数据清理/准备通常分散在许多文件中。这使得跨项目共享和重用精确的拆分和转换成为不可能。\n",
    "\n",
    "LightningDataModule 是管理 PyTorch 闪电中的数据的一种方便方法。它封装了训练、验证、测试和预测数据加载器，以及数据处理、下载和转换的任何必要步骤。通过使用 LightningDataModule，您可以轻松地开发与数据集无关的模型，热交换不同的数据集，并跨项目共享数据分割和转换。\n",
    "\n"
   ],
   "id": "8d923110f26a7a42"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:46:56.063210Z",
     "start_time": "2024-06-11T12:46:56.055950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lightning as L\n",
    "import torch\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Note - you must have torchvision installed for this example\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms"
   ],
   "id": "d3c3c375070a8ab",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 下面是一个简单的 PyTorch 例子:",
   "id": "8bb94e0e74748bad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:46:57.402953Z",
     "start_time": "2024-06-11T12:46:57.358821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# regular PyTorch\n",
    "test_data = MNIST(root=\"MNIST\",train=False, download=True)\n",
    "predict_data = MNIST(root=\"MNIST\", train=False, download=True)\n",
    "train_data = MNIST(root=\"MNIST\", train=True, download=True)\n",
    "train_data, val_data = random_split(train_data, [55000, 5000])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32)\n",
    "val_loader = DataLoader(val_data, batch_size=32)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "predict_loader = DataLoader(predict_data, batch_size=32)"
   ],
   "id": "cbe4dae2e7c29b7b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### LightningDataModule",
   "id": "380aef7ed6dddbe6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:49:56.349286Z",
     "start_time": "2024-06-11T12:49:56.341580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MNISTDataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"MNIST\", batch_size: int = 32):\n",
    "        super().__init__()\n",
    "        self.mnist_val = self.mnist_test = self.mnist_train = None\n",
    "        self.mnist_predict = None\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        self.mnist_test = MNIST(self.data_dir, train=False)\n",
    "        self.mnist_predict = MNIST(self.data_dir, train=False)\n",
    "        mnist_full = MNIST(self.data_dir, train=True)\n",
    "        self.mnist_train, self.mnist_val = torch.utils.data.random_split(\n",
    "            mnist_full, [55000, 5000], generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.mnist_predict, batch_size=self.batch_size)\n",
    "\n",
    "    # def teardown(self, stage: str):\n",
    "    #     # Used to clean-up when the run is finished\n",
    "    #     None"
   ],
   "id": "85b203c9a99cfaf1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "612d4900ff6d5636"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "但是现在，随着处理复杂性的增长(转换，多 GPU 培训) ，你可以让闪电为你处理这些细节，同时让这个数据集可重用，这样你就可以与同事分享或在不同的项目中使用。",
   "id": "ddf42b4f14ffa97a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:50:28.687483Z",
     "start_time": "2024-06-11T12:50:28.683814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# mnist = MNISTDataModule(my_path)\n",
    "# model = LitClassifier()\n",
    "# \n",
    "# trainer = Trainer()\n",
    "# trainer.fit(model, mnist)"
   ],
   "id": "6c2a5c2abfede4f7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "下面是一个更现实、更复杂的 DataModule，它展示了数据模块的可重用性有多大。",
   "id": "8debe2ab18a9e83f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:54:38.880823Z",
     "start_time": "2024-06-11T12:54:38.873811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lightning as L\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Note - you must have torchvision installed for this example\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class MNISTDataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"./\"):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        if stage == \"fit\":\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, self.mnist_val = random_split(\n",
    "                mnist_full, [55000, 5000], generator=torch.Generator().manual_seed(42)\n",
    "            )\n",
    "\n",
    "        # Assign test dataset for use in dataloader(s)\n",
    "        if stage == \"test\":\n",
    "            self.mnist_test = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "        if stage == \"predict\":\n",
    "            self.mnist_predict = MNIST(self.data_dir, train=False, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=32)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=32)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=32)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(self.mnist_predict, batch_size=32)"
   ],
   "id": "176475b8c99f2a38",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LightningDataModule API\n",
    "\n",
    "要定义 DataModule，可以使用以下方法来创建 train/val/test/predict dataloader:\n",
    "\n",
    "- prepare_data (how to download, tokenize, etc…)\n",
    "- setup (how to split, define dataset, etc…)\n",
    "- train_dataloader\n",
    "- val_dataloader\n",
    "- test_dataloader\n",
    "- predict_dataloader"
   ],
   "id": "8b68fc97225a8e85"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## prepare_data\n",
    "\n",
    "Downloading and saving data with multiple processes (distributed settings) will result in corrupted data. Lightning ensures the prepare_data() is called only within a single process on CPU, so you can safely add your downloading logic within. In case of multi-node training, the execution of this hook depends upon prepare_data_per_node. setup() is called after prepare_data and there is a barrier in between which ensures that all the processes proceed to setup once the data is prepared and available for use.\n",
    "\n",
    "使用多个进程(分布式设置)下载和保存数据将导致数据损坏。闪电可以确保 ready _ data ()只在 CPU 上的单个进程中调用，因此您可以安全地在其中添加下载逻辑。在多节点训练的情况下，这个钩子的执行取决于 ready _ data _ per _ node。Setup ()在 ready _ data 之后调用，并且在这两者之间存在一个屏障，以确保在数据准备好并可以使用之后，所有进程都继续进行设置。"
   ],
   "id": "edf236a6356e8fde"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T12:58:02.913043Z",
     "start_time": "2024-06-11T12:58:02.909546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "class MNISTDataModule_example(L.LightningDataModule):\n",
    "    def prepare_data(self):\n",
    "        # download\n",
    "        MNIST(os.getcwd(), train=True, download=True, transform=transforms.ToTensor())\n",
    "        MNIST(os.getcwd(), train=False, download=True, transform=transforms.ToTensor())"
   ],
   "id": "246e21c81320d443",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### WARNING:\n",
    "**从主进程调用 ready _ data。不建议在这里分配 state (例如 self. x = y) ，因为它是在单个进程上调用的，如果在这里分配 state，那么它们对其他进程就不可用。**"
   ],
   "id": "f96b8801b80757e9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## setup\n",
    "\n",
    "还有一些数据操作可能需要在每个 GPU 上执行。使用 setup ()可以执行以下操作:\n",
    "- count number of classes\n",
    "- build vocabulary\n",
    "- perform train/val/test splits\n",
    "- create datasets\n",
    "- apply transforms (defined explicitly in your datamodule)\n",
    "- etc…\n",
    "\n",
    "##### setup is called from every process across all the nodes. Setting state here is recommended.\n",
    "\n",
    "##### teardown can be used to clean up the state. It is also called from every process across all the nodes.\n"
   ],
   "id": "1cb0e3e7bd7a6737"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# transfer_batch_to_device\n",
    "https://lightning.ai/docs/pytorch/stable/data/datamodule.html\n",
    "\n"
   ],
   "id": "fee8450299742531"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def transfer_batch_to_device(self, batch, device, dataloader_idx):\n",
    "    if isinstance(batch, CustomBatch):\n",
    "        # move all tensors in your custom data structure to the device\n",
    "        batch.samples = batch.samples.to(device)\n",
    "        batch.targets = batch.targets.to(device)\n",
    "    elif dataloader_idx == 0:\n",
    "        # skip device transfer for the first dataloader or anything you wish\n",
    "        pass\n",
    "    else:\n",
    "        batch = super().transfer_batch_to_device(batch, device, dataloader_idx)\n",
    "    return batch"
   ],
   "id": "e02781815aba82a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# on_before_batch_transfer\n",
    "\n",
    "Override to alter or apply batch augmentations to your batch before it is transferred to the device.\n",
    "\n",
    "```python\n",
    "def on_before_batch_transfer(self, batch, dataloader_idx):\n",
    "    batch['x'] = transforms(batch['x'])\n",
    "    return batch\n",
    "```\n",
    "\n"
   ],
   "id": "eb48d2453b8aa393"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def on_before_batch_transfer(self, batch, dataloader_idx):\n",
    "    batch['x'] = transforms(batch['x'])\n",
    "    return batch"
   ],
   "id": "d844bc883b660551"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# on_after_batch_transfer\n",
    "\n",
    "在批处理转移到设备后，重写以更改或应用批处理增强。"
   ],
   "id": "3df6ca0b4b8baf6d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def on_after_batch_transfer(self, batch, dataloader_idx):\n",
    "    batch['x'] = gpu_transforms(batch['x'])\n",
    "    return batch"
   ],
   "id": "b1f4b740310d1fc2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# load_state_dict\n",
    "\n",
    "在加载检查点时调用，实现重新加载给定数据模块状态的数据模块状态。"
   ],
   "id": "42c9697fa590781d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# teardown\n",
    "\n",
    "Called at the end of fit (train + validate), validate, test, or predict."
   ],
   "id": "d78c4ffa5876313e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# prepare_data_per_node\n",
    "\n",
    "If set to True will call prepare_data() on LOCAL_RANK=0 for every node. If set to False will only call from NODE_RANK=0, LOCAL_RANK=0."
   ],
   "id": "68326cd6e61fe756"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LitDataModule(L.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.prepare_data_per_node = True"
   ],
   "id": "96ede6919480878a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Using a DataModule\n",
    "\n",
    "The recommended way to use a DataModule is simply:"
   ],
   "id": "bf6c69f07d54fc42"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dm = MNISTDataModule()\n",
    "model = Model()\n",
    "trainer.fit(model, datamodule=dm)\n",
    "trainer.test(datamodule=dm)\n",
    "trainer.validate(datamodule=dm)\n",
    "trainer.predict(datamodule=dm)"
   ],
   "id": "824fc2888fe6249f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 如果需要从数据集中获取信息来构建模型，那么手动运行 ready _ data 和 setup (Light 确保该方法在正确的设备上运行)。",
   "id": "534c96905d6063cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dm = MNISTDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup(stage=\"fit\")\n",
    "\n",
    "model = Model(num_classes=dm.num_classes, width=dm.width, vocab=dm.vocab)\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "dm.setup(stage=\"test\")\n",
    "trainer.test(datamodule=dm)"
   ],
   "id": "174473eb33bae60b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "您可以访问当前使用的数据模块的培训师通过 traner.dataloader 和当前使用的数据加载器通过培训师属性 train _ dataloader () ，val _ dataloader () ，test _ dataloader () ，并预测 _ dataloader ()。",
   "id": "6b34feb818600337"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DataModules without Lightning",
   "id": "62cb9aefc7529d2e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# download, etc...\n",
    "dm = MNISTDataModule()\n",
    "dm.prepare_data()\n",
    "\n",
    "# splits/transforms\n",
    "dm.setup(stage=\"fit\")\n",
    "\n",
    "# use data\n",
    "for batch in dm.train_dataloader():\n",
    "    ...\n",
    "\n",
    "for batch in dm.val_dataloader():\n",
    "    ...\n",
    "\n",
    "dm.teardown(stage=\"fit\")\n",
    "\n",
    "# lazy load test data\n",
    "dm.setup(stage=\"test\")\n",
    "for batch in dm.test_dataloader():\n",
    "    ...\n",
    "\n",
    "dm.teardown(stage=\"test\")"
   ],
   "id": "e683d75ef070223b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hyperparameters in DataModules",
   "id": "892dfcb12b37bf8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import lightning as L\n",
    "\n",
    "\n",
    "class CustomDataModule(L.LightningDataModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # access the saved hyperparameters\n",
    "        opt = optim.Adam(self.parameters(), lr=self.hparams.lr)"
   ],
   "id": "64148defa9c3e76f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Save DataModule state\n",
    "\n",
    "When a checkpoint is created, it asks every DataModule for their state. If your DataModule defines the state_dict and load_state_dict methods, the checkpoint will automatically track and restore your DataModules.\n",
    "\n",
    "创建检查点时，它会询问每个 DataModule 的状态。如果 DataModule 定义 state _ dict 和 load _ state _ dict 方法，则检查点将自动跟踪和还原 DataModule。"
   ],
   "id": "b9998d4e22c30d57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T14:25:50.124100Z",
     "start_time": "2024-06-11T14:25:50.121239Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lightning as L\n",
    "\n",
    "\n",
    "class LitDataModule(L.LightningDataModule):\n",
    "    def state_dict(self):\n",
    "        # track whatever you want here\n",
    "        state = {\"current_train_batch_index\": self.current_train_batch_index}\n",
    "        return state\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        # restore the state based on what you tracked in (def state_dict)\n",
    "        self.current_train_batch_index = state_dict[\"current_train_batch_index\"]"
   ],
   "id": "5bb06f167e3e1a93",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e402084cbe0e92cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vp",
   "language": "python",
   "name": "vp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
