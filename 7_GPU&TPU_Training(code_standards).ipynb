{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# HARDWARE AGNOSTIC TRAINING (PREPARATION) 硬件不可知训练(准备)\n",
    "\n",
    "To train on CPU/GPU/TPU without changing your code, we need to build a few good habits :)\n",
    "\n",
    "要在 CPU/GPU/TPU 上训练而不改变代码，我们需要养成一些好习惯:)"
   ],
   "id": "c4deacc8586e2ac4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Delete .cuda() or .to() calls\n",
    "\n",
    "**Delete any calls to .cuda() or .to(device).**\n",
    "\n",
    "```python\n",
    "# before lightning\n",
    "def forward(self, x):\n",
    "    x = x.cuda(0)\n",
    "    layer_1.cuda(0)\n",
    "    x_hat = layer_1(x)\n",
    "\n",
    "\n",
    "# after lightning\n",
    "def forward(self, x):\n",
    "    x_hat = layer_1(x)\n",
    "```"
   ],
   "id": "4eafe4a1fd53f82f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Init tensors using Tensor.to and register_buffer\n",
    "\n",
    "When you need to create a new tensor, use Tensor.to. This will make your code scale to any arbitrary number of GPUs or TPUs with Lightning.\n",
    "\n",
    "当您需要创建一个新的张量时，使用 **Tensor.to**。这将使您的代码扩展到任意数量的 GPU 或带闪电的 TPU。\n",
    "\n",
    "```python\n",
    "# before lightning\n",
    "def forward(self, x):\n",
    "    z = torch.Tensor(2, 3)\n",
    "    z = z.cuda(0)\n",
    "\n",
    "\n",
    "# with lightning\n",
    "def forward(self, x):\n",
    "    z = torch.Tensor(2, 3)\n",
    "    z = z.to(x)\n",
    "```"
   ],
   "id": "bc76765da46e3610"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The `LightningModule` knows what device it is on. You can access the reference `via self.device`. Sometimes it is necessary to store tensors as module attributes. ** However, if they are not parameters they will remain on the CPU even if the module gets moved to a new device.** To prevent that and remain device agnostic, register the tensor as a buffer in your modules’ __init__ method with register_buffer().\n",
    "\n",
    "LightningModule 知道它在哪个设备上。您可以通过 self. device 访问引用。有时需要将张量存储为模属性。但是，如果它们不是参数，即使模块被移动到新设备上，它们也会保留在 CPU 上。为了避免这种情况并保持设备不可知性，可以使用 register _ buffer ()在模块的 _ _ init _ _ 方法中将张量注册为缓冲区。\n",
    "\n",
    "```python\n",
    "class LitModel(LightningModule):\n",
    "    def __init__(self):\n",
    "        ...\n",
    "        self.register_buffer(\"sigma\", torch.eye(3))\n",
    "        # you can now access self.sigma anywhere in your module\n",
    "```"
   ],
   "id": "bc74941329ff041d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Remove samplers\n",
    "\n",
    "DistributedSampler is automatically handled by Lightning.\n",
    "\n",
    "Lightning 将会自动完成分布式训练；"
   ],
   "id": "3c1fcb8be9404be5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Synchronize validation and test logging 同步验证和测试日志记录\n",
    "\n",
    "When running in distributed mode, we have to ensure that the validation and test step logging calls are synchronized across processes. This is done by adding `sync_dist=True` to `all self.log` calls in the validation and test step. This ensures that each GPU worker has the same behaviour when tracking model checkpoints, which is important for later downstream tasks such as testing the best checkpoint across all workers. The sync_dist option can also be used in logging calls during the step methods, but be aware that this can lead to significant communication overhead and slow down your training.\n",
    "\n",
    "在分布式模式下运行时，我们必须确保验证和测试步骤日志记录调用跨进程同步。这是通过在验证和测试步骤中将 sync _ dist = True 添加到所有 self. log 调用来完成的。这样可以确保每个 GPU 工作人员在跟踪模型检查点时具有相同的行为，这对后续任务(例如测试所有工作人员的最佳检查点)很重要。Sync _ dist 选项也可以用于在步骤方法期间记录调用，但是请注意，这可能导致显著的通信开销，并减慢您的培训。\n",
    "\n",
    "Note if you use any built in metrics or custom metrics that use TorchMetrics, these do not need to be updated and are automatically handled for you.\n",
    "\n",
    "注意，如果您使用任何使用 TorchMetrics 的内置指标或自定义指标，则不需要更新这些指标，它们将自动为您处理。"
   ],
   "id": "abfc677d780335a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T08:00:38.183169Z",
     "start_time": "2024-06-11T08:00:38.175795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def validation_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    logits = self(x)\n",
    "    loss = self.loss(logits, y)\n",
    "    # Add sync_dist=True to sync logging across all GPU workers (may have performance impact)\n",
    "    self.log(\"validation_loss\", loss, on_step=True, on_epoch=True, sync_dist=True)\n",
    "\n",
    "\n",
    "def test_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    logits = self(x)\n",
    "    loss = self.loss(logits, y)\n",
    "    # Add sync_dist=True to sync logging across all GPU workers (may have performance impact)\n",
    "    self.log(\"test_loss\", loss, on_step=True, on_epoch=True, sync_dist=True)"
   ],
   "id": "eb9d5301e2f16d19",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It is possible to perform some computation manually and log the reduced result on rank 0 as follows:\n",
    "\n",
    "可以手工进行一些计算，并将降低后的结果记录在0级上，如下所示:"
   ],
   "id": "f19f9baaba079fc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def __init__(self):\n",
    "    super().__init__()\n",
    "    self.outputs = []\n",
    "\n",
    "\n",
    "def test_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    tensors = self(x)\n",
    "    self.outputs.append(tensors)\n",
    "    return tensors\n",
    "\n",
    "\n",
    "def on_test_epoch_end(self):\n",
    "    mean = torch.mean(self.all_gather(self.outputs))\n",
    "    self.outputs.clear()  # free memory\n",
    "\n",
    "    # When you call `self.log` only on rank 0, don't forget to badd\n",
    "    # `rank_zero_only=True` to avoid deadlocks on synchronization.\n",
    "    # Caveat: monitoring this is unimplemented, see https://github.com/Lightning-AI/lightning/issues/15852\n",
    "    if self.trainer.is_global_zero:\n",
    "        self.log(\"my_reduced_metric\", mean, rank_zero_only=True)"
   ],
   "id": "78ea8b798d7027c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Make models pickleable 让模特变得可以pickleable（序列化？）\n",
    "\n",
    "It’s very likely your code is already pickleable, in that case no change in necessary. However, if you run a distributed model and get the following error:\n",
    "\n",
    "您的代码很可能已经是可pickle的，在这种情况下不需要进行任何更改。但是，如果您运行一个分布式模型并得到以下错误:\n",
    "\n",
    "```\n",
    "self._launch(process_obj)\n",
    "File \"/net/software/local/python/3.6.5/lib/python3.6/multiprocessing/popen_spawn_posix.py\", line 47,\n",
    "in _launch reduction.dump(process_obj, fp)\n",
    "File \"/net/software/local/python/3.6.5/lib/python3.6/multiprocessing/reduction.py\", line 60, in dump\n",
    "ForkingPickler(file, protocol).dump(obj)\n",
    "_pickle.PicklingError: Can't pickle <function <lambda> at 0x2b599e088ae8>:\n",
    "attribute lookup <lambda> on __main__ failed\n",
    "```\n",
    "\n",
    "This means something in your model definition, transforms, optimizer, dataloader or callbacks cannot be pickled, and the following code will fail:\n",
    "\n",
    "这意味着模型定义、转换、优化器、数据加载器或回调中的某些内容不能被 pickle，并且下面的代码将会失败:\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "pickle.dump(some_object)\n",
    "```\n",
    "\n",
    "这是在 PyTorch 中使用多个进程进行分布式培训的一个限制。若要修复此问题，请找到无法腌制的代码段。堆栈跟踪的结尾通常是有帮助的。例如: 在这里的 stacktrace 示例中，似乎在代码的某个地方有一个 lambda 函数，它不能被 pickle。"
   ],
   "id": "2a17983c91d2d3d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# GPU TRAINING (BASIC)\n",
    "\n",
    "## Train on GPUs\n",
    "\n",
    "在默认情况下，Trainer 将在所有可用的 GPU 上运行。确保您在至少有一个 GPU 的机器上运行。没有必要指定任何 NVIDIA 标志，因为闪电将为您做到这一点。"
   ],
   "id": "5b9ccce8113accc7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T08:09:14.691692Z",
     "start_time": "2024-06-11T08:09:10.650865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import lightning as L\n",
    "from lightning import Trainer\n",
    "# run on as many GPUs as available by default\n",
    "trainer = Trainer(accelerator=\"auto\", devices=\"auto\", strategy=\"auto\")\n",
    "# equivalent to\n",
    "trainer = Trainer()\n",
    "\n",
    "# run on one GPU\n",
    "trainer = Trainer(accelerator=\"gpu\", devices=1)\n",
    "# run on multiple GPUs\n",
    "trainer = Trainer(accelerator=\"gpu\", devices=8)\n",
    "# choose the number of devices automatically\n",
    "trainer = Trainer(accelerator=\"gpu\", devices=\"auto\")"
   ],
   "id": "420da490e883ffc7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\alpha\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "You requested gpu: [0, 1, 2, 3, 4, 5, 6, 7]\n But your machine only has: [0]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMisconfigurationException\u001B[0m                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m\"\u001B[39m, devices\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# run on multiple GPUs\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m trainer \u001B[38;5;241m=\u001B[39m \u001B[43mTrainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgpu\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m8\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# choose the number of devices automatically\u001B[39;00m\n\u001B[0;32m     13\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(accelerator\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpu\u001B[39m\u001B[38;5;124m\"\u001B[39m, devices\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\pytorch\\utilities\\argparse.py:70\u001B[0m, in \u001B[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mlist\u001B[39m(env_variables\u001B[38;5;241m.\u001B[39mitems()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mlist\u001B[39m(kwargs\u001B[38;5;241m.\u001B[39mitems()))\n\u001B[0;32m     69\u001B[0m \u001B[38;5;66;03m# all args were already moved to kwargs\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:401\u001B[0m, in \u001B[0;36mTrainer.__init__\u001B[1;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001B[0m\n\u001B[0;32m    398\u001B[0m \u001B[38;5;66;03m# init connectors\u001B[39;00m\n\u001B[0;32m    399\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_connector \u001B[38;5;241m=\u001B[39m _DataConnector(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 401\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accelerator_connector \u001B[38;5;241m=\u001B[39m \u001B[43m_AcceleratorConnector\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    402\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdevices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    403\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccelerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccelerator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_nodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_nodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[43m    \u001B[49m\u001B[43msync_batchnorm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msync_batchnorm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    407\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbenchmark\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbenchmark\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_distributed_sampler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_distributed_sampler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdeterministic\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdeterministic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprecision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprecision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    411\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplugins\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mplugins\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    412\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    413\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_logger_connector \u001B[38;5;241m=\u001B[39m _LoggerConnector(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    414\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_callback_connector \u001B[38;5;241m=\u001B[39m _CallbackConnector(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py:150\u001B[0m, in \u001B[0;36m_AcceleratorConnector.__init__\u001B[1;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001B[0m\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accelerator_flag \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_choose_gpu_accelerator_backend()\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_device_config_and_set_final_flags(devices\u001B[38;5;241m=\u001B[39mdevices, num_nodes\u001B[38;5;241m=\u001B[39mnum_nodes)\n\u001B[1;32m--> 150\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_parallel_devices_and_init_accelerator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    152\u001B[0m \u001B[38;5;66;03m# 3. Instantiate ClusterEnvironment\u001B[39;00m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcluster_environment: ClusterEnvironment \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_choose_and_init_cluster_environment()\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\accelerator_connector.py:390\u001B[0m, in \u001B[0;36m_AcceleratorConnector._set_parallel_devices_and_init_accelerator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    382\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MisconfigurationException(\n\u001B[0;32m    383\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maccelerator_cls\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` can not run on your system\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    384\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m since the accelerator is not available. The following accelerator(s)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    385\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is available and can be passed into `accelerator` argument of\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    386\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m `Trainer`: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mavailable_accelerator\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    387\u001B[0m     )\n\u001B[0;32m    389\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_devices_flag_if_auto_passed()\n\u001B[1;32m--> 390\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_devices_flag \u001B[38;5;241m=\u001B[39m \u001B[43maccelerator_cls\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_devices\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_devices_flag\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    391\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parallel_devices:\n\u001B[0;32m    392\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parallel_devices \u001B[38;5;241m=\u001B[39m accelerator_cls\u001B[38;5;241m.\u001B[39mget_parallel_devices(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_devices_flag)\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\pytorch\\accelerators\\cuda.py:88\u001B[0m, in \u001B[0;36mCUDAAccelerator.parse_devices\u001B[1;34m(devices)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;129m@override\u001B[39m\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse_devices\u001B[39m(devices: Union[\u001B[38;5;28mint\u001B[39m, \u001B[38;5;28mstr\u001B[39m, List[\u001B[38;5;28mint\u001B[39m]]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Optional[List[\u001B[38;5;28mint\u001B[39m]]:\n\u001B[0;32m     87\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Accelerator device parsing logic.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_parse_gpu_ids\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_cuda\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\fabric\\utilities\\device_parser.py:102\u001B[0m, in \u001B[0;36m_parse_gpu_ids\u001B[1;34m(gpus, include_cuda, include_mps)\u001B[0m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;66;03m# Check that GPUs are unique. Duplicate GPUs are not supported by the backend.\u001B[39;00m\n\u001B[0;32m    100\u001B[0m _check_unique(gpus)\n\u001B[1;32m--> 102\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_sanitize_gpu_ids\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgpus\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_cuda\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_cuda\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minclude_mps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minclude_mps\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\fabric\\utilities\\device_parser.py:135\u001B[0m, in \u001B[0;36m_sanitize_gpu_ids\u001B[1;34m(gpus, include_cuda, include_mps)\u001B[0m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m gpu \u001B[38;5;129;01min\u001B[39;00m gpus:\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gpu \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m all_available_gpus:\n\u001B[1;32m--> 135\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m MisconfigurationException(\n\u001B[0;32m    136\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou requested gpu: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgpus\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m But your machine only has: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mall_available_gpus\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    137\u001B[0m         )\n\u001B[0;32m    138\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m gpus\n",
      "\u001B[1;31mMisconfigurationException\u001B[0m: You requested gpu: [0, 1, 2, 3, 4, 5, 6, 7]\n But your machine only has: [0]"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Choosing GPU devices\n",
    "https://lightning.ai/docs/pytorch/stable/accelerators/gpu_basic.html\n",
    "\n",
    "\n",
    "You can select the GPU devices using ranges, a list of indices or a string containing a comma separated list of GPU ids:\n",
    "\n",
    "您可以使用范围、索引列表或包含逗号分隔的 GPU id 列表的字符串来选择 GPU 设备:\n",
    "\n",
    "```python\n",
    "# DEFAULT (int) specifies how many GPUs to use per node\n",
    "Trainer(accelerator=\"gpu\", devices=k)\n",
    "\n",
    "# Above is equivalent to\n",
    "Trainer(accelerator=\"gpu\", devices=list(range(k)))\n",
    "\n",
    "# Specify which GPUs to use (don't use when running on cluster)\n",
    "Trainer(accelerator=\"gpu\", devices=[0, 1])\n",
    "\n",
    "# Equivalent using a string\n",
    "Trainer(accelerator=\"gpu\", devices=\"0, 1\")\n",
    "\n",
    "# To use all available GPUs put -1 or '-1'\n",
    "# equivalent to `list(range(torch.cuda.device_count())) and `\"auto\"`\n",
    "Trainer(accelerator=\"gpu\", devices=-1)\n",
    "```"
   ],
   "id": "42237fb79491ce82"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Find usable CUDA devices\n",
    "\n",
    "If you want to run several experiments at the same time on your machine, for example for a hyperparameter sweep, then you can use the following utility function to pick GPU indices that are “accessible”, without having to change your code every time.\n",
    "\n",
    "如果你想在你的机器上同时运行几个实验，比如超参数扫描，那么你可以使用下面的实用函数来选择可访问的 GPU 索引，而不必每次都更改你的代码。\n",
    "\n",
    "This is especially useful when GPUs are configured to be in “exclusive compute mode”, such that only one process at a time is allowed access to the device. This special mode is often enabled on server GPUs or systems shared among multiple users.\n",
    "\n",
    "当 GPU 被配置为“独占计算模式”时，这尤其有用，因为一次只允许一个进程访问设备。这种特殊模式通常在服务器 GPU 或多个用户共享的系统上启用。"
   ],
   "id": "c4a261411e9e4396"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T08:30:09.038447Z",
     "start_time": "2024-06-11T08:30:09.019163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lightning.pytorch.accelerators import find_usable_cuda_devices\n",
    "\n",
    "# Find two GPUs on the system that are not already occupied\n",
    "trainer = Trainer(accelerator=\"cuda\", devices=find_usable_cuda_devices(1))\n",
    "\n",
    "from lightning.fabric.accelerators import find_usable_cuda_devices\n",
    "\n",
    "# Works with Fabric too\n",
    "fabric = L.Fabric(accelerator=\"cuda\", devices=find_usable_cuda_devices(1))"
   ],
   "id": "a6d404a08833f7b1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "11f656dd6854fbc0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vp",
   "language": "python",
   "name": "vp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
