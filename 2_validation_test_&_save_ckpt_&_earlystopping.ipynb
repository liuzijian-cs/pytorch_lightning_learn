{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-10T03:56:03.846886Z",
     "start_time": "2024-06-10T03:56:03.843005Z"
    }
   },
   "source": [
    "from json import encoder\n",
    "\n",
    "import torch.utils.data as data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as L"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T03:56:04.236771Z",
     "start_time": "2024-06-10T03:56:04.204512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data sets\n",
    "transform = transforms.ToTensor()\n",
    "train_set = datasets.MNIST(root=\"MNIST\", download=True, train=True, transform=transform)\n",
    "test_set = datasets.MNIST(root=\"MNIST\", download=True, train=False, transform=transform)"
   ],
   "id": "82b05a69b9a6324",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T03:56:05.126540Z",
     "start_time": "2024-06-10T03:56:05.122319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PyTorch\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l1(x)"
   ],
   "id": "b5f9e49f40fdf899",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T03:56:06.880867Z",
     "start_time": "2024-06-10T03:56:06.878273Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1fa7d25c7487c8d7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Define the test loop",
   "id": "94a79f8b4fc4a67c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T07:12:46.427075Z",
     "start_time": "2024-06-10T07:12:46.421522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# PyTorch-Lightning\n",
    "class LitAutoEncoder(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        test_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        val_loss = F.mse_loss(x_hat, x)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    "
   ],
   "id": "afe6f2508afc3aa",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T03:56:25.941624Z",
     "start_time": "2024-06-10T03:56:08.366497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# initialize the Trainer\n",
    "trainer = L.Trainer()\n",
    "model = LitAutoEncoder(Encoder(), Decoder())\n",
    "\n",
    "# test the model\n",
    "trainer.test(model, dataloaders=DataLoader(test_set))"
   ],
   "id": "3c7284b71341c66",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\alpha\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\logger_connector\\logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Ti SUPER') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\alpha\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:441: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Testing: |                                                                                                    …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0e3ca3f9b7d54cdf945bb6bf4f07e5db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Add a validation loop",
   "id": "14bd11496c9bd844"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T03:56:40.040309Z",
     "start_time": "2024-06-10T03:56:40.034279Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# use a0% of training data for validation\n",
    "train_set_size = int(len(train_set) * 0.8)\n",
    "valid_set_size = len(train_set) - train_set_size\n",
    "\n",
    "# split the train set into two\n",
    "seed = torch.Generator().manual_seed(42)\n",
    "train_set, valid_set = data.random_split(train_set, [train_set_size, valid_set_size], generator=seed)"
   ],
   "id": "b253e8ee73197e5d",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T04:02:23.558Z",
     "start_time": "2024-06-10T04:02:00.269155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_set,num_workers=0, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set,num_workers=0, batch_size=64, shuffle=True)\n",
    "model = LitAutoEncoder(Encoder(), Decoder())\n",
    "\n",
    "# train with both splits\n",
    "trainer = L.Trainer(accelerator='gpu', max_epochs=3)\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ],
   "id": "9e4a6b158fe29f6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K\n",
      "1 | decoder | Decoder | 51.2 K\n",
      "------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7be4de42d2ce4c868b310c48f0ab0d76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training: |                                                                                                   …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ac3467ec833419988ce3f5fec59323c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e58fb98c227c4ba59e5d69ae0609db96"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7c20728557146359963959aa080b696"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a4c5aa41a784875937c5447ef8998d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T03:57:39.349544Z",
     "start_time": "2024-06-10T03:57:39.346135Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()\n",
   "id": "8c631f94cb608482",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# What is a checkpoint?\n",
    "When a model is training, the performance changes as it continues to see more data. It is a best practice to save the state of a model throughout the training process. This gives you a version of the model, a checkpoint, at each key point during the development of the model. Once training has completed, use the checkpoint that corresponds to the best performance you found during the training process.\n",
    "\n",
    "Checkpoints also enable your training to resume from where it was in case the training process is interrupted.\n",
    "\n",
    "PyTorch Lightning checkpoints are fully usable in plain PyTorch.\n",
    "\n",
    "> 当一个模型正在训练时，性能随着它继续看到更多的数据而改变。在整个培训过程中保存模型的状态是一种最佳实践。这将在模型开发期间的每个关键点为您提供模型的一个版本，即一个检查点。一旦培训完成，使用与培训过程中发现的最佳性能相对应的检查点。检查点还可以使您的培训从原来的地方恢复，以防培训过程中断。火炬闪电检查点在普通火炬中是完全可用的。"
   ],
   "id": "dfec9dbe8a258b2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Contents of a checkpoint\n",
    "\n",
    "A Lightning checkpoint contains a dump of the model’s entire internal state. Unlike plain PyTorch, Lightning saves everything you need to restore a model even in the most complex distributed training environments.\n",
    "\n",
    "> “闪电”检查点包含模型整个内部状态的转储。与普通的 PyTorch 不同，即使在最复杂的分布式培训环境中，“闪电”也会保存恢复模型所需的所有内容。\n",
    "\n",
    "Inside a Lightning checkpoint you’ll find:\n",
    "- 16-bit scaling factor (if using 16-bit precision training) / 16位缩放因子\n",
    "- Current epoch\n",
    "- Global step\n",
    "- LightningModule’s state_dict\n",
    "- State of all optimizers\n",
    "- State of all learning rate schedulers\n",
    "- State of all callbacks (for stateful callbacks)\n",
    "- State of datamodule (for stateful datamodules)\n",
    "- The hyperparameters (init arguments) with which the model was created\n",
    "- The hyperparameters (init arguments) with which the datamodule was created\n",
    "- State of Loops"
   ],
   "id": "567145f0d4218e4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Save a checkpoint\n",
    "# simply by using the Trainer you get automatic checkpointing\n",
    "`trainer = Trainer()`\n",
    "# saves checkpoints to 'some/path/' at every epoch end\n",
    "`trainer = Trainer(default_root_dir=\"some/path/\")`"
   ],
   "id": "80e0cea79698639d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T04:08:12.500977Z",
     "start_time": "2024-06-10T04:07:49.193835Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer = L.Trainer(accelerator='gpu', max_epochs=3, default_root_dir='./ckpts')\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ],
   "id": "b44bb98689007e93",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: ckpts\\lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K\n",
      "1 | decoder | Decoder | 51.2 K\n",
      "------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22efc76be97044b3919137fdb30c4eae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training: |                                                                                                   …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a9179c81398147868ad04c71207e193f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ea7fe3ae063a4a708f28f9ddaca72f94"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "174bd90f6bc2440fa072e2583c3d92aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e01e3d8f9d64fa5b86faed7c8262b5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=3` reached.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T04:17:49.899673Z",
     "start_time": "2024-06-10T04:17:49.869920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "model = LitAutoEncoder(Encoder(), Decoder()).load_from_checkpoint(\"ckpts/lightning_logs/version_0/checkpoints/epoch=2-step=2250.ckpt\")\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n"
   ],
   "id": "691dee8f0ac916bc",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The classmethod `LitAutoEncoder.load_from_checkpoint` cannot be called on an instance. Please call it on the class type and make sure the return value is used.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mLitAutoEncoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43mEncoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mDecoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mckpts/lightning_logs/version_0/checkpoints/epoch=2-step=2250.ckpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# disable randomness, dropout, etc...\u001B[39;00m\n\u001B[0;32m      3\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\pytorch\\utilities\\model_helpers.py:121\u001B[0m, in \u001B[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m is_scripting \u001B[38;5;241m=\u001B[39m \u001B[38;5;28many\u001B[39m(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjit\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01min\u001B[39;00m frameinfo\u001B[38;5;241m.\u001B[39mfilename \u001B[38;5;28;01mfor\u001B[39;00m frameinfo \u001B[38;5;129;01min\u001B[39;00m inspect\u001B[38;5;241m.\u001B[39mstack())\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m instance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scripting:\n\u001B[1;32m--> 121\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    122\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe classmethod `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` cannot be called on an instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    123\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Please call it on the class type and make sure the return value is used.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    124\u001B[0m     )\n\u001B[0;32m    125\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mTypeError\u001B[0m: The classmethod `LitAutoEncoder.load_from_checkpoint` cannot be called on an instance. Please call it on the class type and make sure the return value is used."
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T04:18:53.634062Z",
     "start_time": "2024-06-10T04:18:53.616984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint = torch.load(\"ckpts/lightning_logs/version_0/checkpoints/epoch=2-step=2250.ckpt\", map_location=lambda storage, loc: storage)\n",
    "print(checkpoint[\"hyper_parameters\"])"
   ],
   "id": "5bfd977e5cb376d6",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'hyper_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m checkpoint \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mckpts/lightning_logs/version_0/checkpoints/epoch=2-step=2250.ckpt\u001B[39m\u001B[38;5;124m\"\u001B[39m, map_location\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m storage, loc: storage)\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mcheckpoint\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhyper_parameters\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'hyper_parameters'"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save hyperparameters",
   "id": "3667aa24495bb11b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T04:19:25.806238Z",
     "start_time": "2024-06-10T04:19:25.802613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MyLightningModule(L.LightningModule):\n",
    "    def __init__(self, learning_rate, another_parameter, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()"
   ],
   "id": "7cb22068906ba960",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T04:19:30.738130Z",
     "start_time": "2024-06-10T04:19:30.642597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint = torch.load(checkpoint, map_location=lambda storage, loc: storage)\n",
    "print(checkpoint[\"hyper_parameters\"])\n",
    "# {\"learning_rate\": the_value, \"another_parameter\": the_other_value}"
   ],
   "id": "ca916ebf79a53638",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\torch\\serialization.py:540\u001B[0m, in \u001B[0;36m_check_seekable\u001B[1;34m(f)\u001B[0m\n\u001B[0;32m    539\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 540\u001B[0m     \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mseek\u001B[49m(f\u001B[38;5;241m.\u001B[39mtell())\n\u001B[0;32m    541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'dict' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[27], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m checkpoint \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloc\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(checkpoint[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhyper_parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# {\"learning_rate\": the_value, \"another_parameter\": the_other_value}\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\torch\\serialization.py:997\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m    994\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    995\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 997\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m    998\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m    999\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m   1000\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m   1001\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m   1002\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\torch\\serialization.py:449\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    447\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _open_buffer_writer(name_or_buffer)\n\u001B[0;32m    448\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m--> 449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_buffer_reader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    450\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    451\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m in mode but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmode\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\torch\\serialization.py:434\u001B[0m, in \u001B[0;36m_open_buffer_reader.__init__\u001B[1;34m(self, buffer)\u001B[0m\n\u001B[0;32m    432\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, buffer):\n\u001B[0;32m    433\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(buffer)\n\u001B[1;32m--> 434\u001B[0m     \u001B[43m_check_seekable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\torch\\serialization.py:543\u001B[0m, in \u001B[0;36m_check_seekable\u001B[1;34m(f)\u001B[0m\n\u001B[0;32m    541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    542\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (io\u001B[38;5;241m.\u001B[39mUnsupportedOperation, \u001B[38;5;167;01mAttributeError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 543\u001B[0m     \u001B[43mraise_err_msg\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mseek\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtell\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43me\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    544\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\torch\\serialization.py:536\u001B[0m, in \u001B[0;36m_check_seekable.<locals>.raise_err_msg\u001B[1;34m(patterns, e)\u001B[0m\n\u001B[0;32m    532\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e):\n\u001B[0;32m    533\u001B[0m         msg \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m. You can only torch.load from a file that is seekable.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    534\u001B[0m                         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Please pre-load the data into a buffer like io.BytesIO and\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    535\u001B[0m                         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m try to load from it instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 536\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(e)(msg)\n\u001B[0;32m    537\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'dict' object has no attribute 'seek'. You can only torch.load from a file that is seekable. Please pre-load the data into a buffer like io.BytesIO and try to load from it instead."
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T04:19:40.303578Z",
     "start_time": "2024-06-10T04:19:40.239809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MyLightningModule.load_from_checkpoint(\"/path/to/checkpoint.ckpt\")\n",
    "print(model.learning_rate)"
   ],
   "id": "beca1898bc7e32d2",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/path/to/checkpoint.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mMyLightningModule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/path/to/checkpoint.ckpt\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(model\u001B[38;5;241m.\u001B[39mlearning_rate)\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\pytorch\\utilities\\model_helpers.py:125\u001B[0m, in \u001B[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    120\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m instance \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_scripting:\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    122\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe classmethod `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmethod\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` cannot be called on an instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    123\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Please call it on the class type and make sure the return value is used.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    124\u001B[0m     )\n\u001B[1;32m--> 125\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\pytorch\\core\\module.py:1581\u001B[0m, in \u001B[0;36mLightningModule.load_from_checkpoint\u001B[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[0;32m   1492\u001B[0m \u001B[38;5;129m@_restricted_classmethod\u001B[39m\n\u001B[0;32m   1493\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_from_checkpoint\u001B[39m(\n\u001B[0;32m   1494\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1499\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m   1500\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Self:\n\u001B[0;32m   1501\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001B[39;00m\n\u001B[0;32m   1502\u001B[0m \u001B[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001B[39;00m\n\u001B[0;32m   1503\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1579\u001B[0m \n\u001B[0;32m   1580\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1581\u001B[0m     loaded \u001B[38;5;241m=\u001B[39m \u001B[43m_load_from_checkpoint\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1582\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m   1583\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1584\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1585\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhparams_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1586\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1587\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1588\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1589\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(Self, loaded)\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\pytorch\\core\\saving.py:63\u001B[0m, in \u001B[0;36m_load_from_checkpoint\u001B[1;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001B[0m\n\u001B[0;32m     61\u001B[0m map_location \u001B[38;5;241m=\u001B[39m map_location \u001B[38;5;129;01mor\u001B[39;00m _default_map_location\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pl_legacy_patch():\n\u001B[1;32m---> 63\u001B[0m     checkpoint \u001B[38;5;241m=\u001B[39m \u001B[43mpl_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcheckpoint_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmap_location\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;66;03m# convert legacy checkpoints to the new format\u001B[39;00m\n\u001B[0;32m     66\u001B[0m checkpoint \u001B[38;5;241m=\u001B[39m _pl_migrate_checkpoint(\n\u001B[0;32m     67\u001B[0m     checkpoint, checkpoint_path\u001B[38;5;241m=\u001B[39m(checkpoint_path \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(checkpoint_path, (\u001B[38;5;28mstr\u001B[39m, Path)) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     68\u001B[0m )\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\lightning\\fabric\\utilities\\cloud_io.py:56\u001B[0m, in \u001B[0;36m_load\u001B[1;34m(path_or_url, map_location)\u001B[0m\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mhub\u001B[38;5;241m.\u001B[39mload_state_dict_from_url(\n\u001B[0;32m     52\u001B[0m         \u001B[38;5;28mstr\u001B[39m(path_or_url),\n\u001B[0;32m     53\u001B[0m         map_location\u001B[38;5;241m=\u001B[39mmap_location,  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m     54\u001B[0m     )\n\u001B[0;32m     55\u001B[0m fs \u001B[38;5;241m=\u001B[39m get_filesystem(path_or_url)\n\u001B[1;32m---> 56\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mfs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_url\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m     57\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mload(f, map_location\u001B[38;5;241m=\u001B[39mmap_location)\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\fsspec\\spec.py:1303\u001B[0m, in \u001B[0;36mAbstractFileSystem.open\u001B[1;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001B[0m\n\u001B[0;32m   1301\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1302\u001B[0m     ac \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mautocommit\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_intrans)\n\u001B[1;32m-> 1303\u001B[0m     f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1304\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1305\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1306\u001B[0m \u001B[43m        \u001B[49m\u001B[43mblock_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblock_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1307\u001B[0m \u001B[43m        \u001B[49m\u001B[43mautocommit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mac\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1308\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1309\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1310\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m compression \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1312\u001B[0m         \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfsspec\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompression\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m compr\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\fsspec\\implementations\\local.py:191\u001B[0m, in \u001B[0;36mLocalFileSystem._open\u001B[1;34m(self, path, mode, block_size, **kwargs)\u001B[0m\n\u001B[0;32m    189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_mkdir \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m    190\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmakedirs(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent(path), exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m--> 191\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mLocalFileOpener\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\fsspec\\implementations\\local.py:355\u001B[0m, in \u001B[0;36mLocalFileOpener.__init__\u001B[1;34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001B[0m\n\u001B[0;32m    353\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression \u001B[38;5;241m=\u001B[39m get_compression(path, compression)\n\u001B[0;32m    354\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocksize \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mDEFAULT_BUFFER_SIZE\n\u001B[1;32m--> 355\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\vp\\Lib\\site-packages\\fsspec\\implementations\\local.py:360\u001B[0m, in \u001B[0;36mLocalFileOpener._open\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf\u001B[38;5;241m.\u001B[39mclosed:\n\u001B[0;32m    359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mautocommit \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m--> 360\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpath, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode)\n\u001B[0;32m    361\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression:\n\u001B[0;32m    362\u001B[0m             compress \u001B[38;5;241m=\u001B[39m compr[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompression]\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'C:/path/to/checkpoint.ckpt'"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Initialize with other parameters\n",
    "> 在某些情况下，我们还可以将整个 PyTorch 模块传递给 _ _ init _ _ 方法，由于它们的大小，您不希望将它们保存为超参数。如果您没有调用 self. save _ hyper旦()或者通过 save _ hyper旦忽略参数(忽略 = ...) ，那么在调用 load _ from _ check 方法时，您必须传递缺少的位置参数或关键字参数:"
   ],
   "id": "15a2660a38bc76e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T04:20:13.925228Z",
     "start_time": "2024-06-10T04:20:13.910433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# if you train and save the model like this it will use these values when loading\n",
    "# the weights. But you can overwrite this\n",
    "LitModel(in_dim=32, out_dim=10)\n",
    "\n",
    "# uses in_dim=32, out_dim=10\n",
    "model = LitModel.load_from_checkpoint(PATH)\n",
    "\n",
    "# uses in_dim=128, out_dim=10\n",
    "model = LitModel.load_from_checkpoint(PATH, in_dim=128, out_dim=10)"
   ],
   "id": "d7136689e7868a4e",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LitModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[29], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# if you train and save the model like this it will use these values when loading\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# the weights. But you can overwrite this\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[43mLitModel\u001B[49m(in_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, out_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# uses in_dim=32, out_dim=10\u001B[39;00m\n\u001B[0;32m      6\u001B[0m model \u001B[38;5;241m=\u001B[39m LitModel\u001B[38;5;241m.\u001B[39mload_from_checkpoint(PATH)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'LitModel' is not defined"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T04:21:12.901679Z",
     "start_time": "2024-06-10T04:21:12.885702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class LitAutoencoder(L.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        ...\n",
    "\n",
    "    ...\n",
    "\n",
    "\n",
    "model = LitAutoEncoder.load_/from_checkpoint(PATH, encoder=encoder, decoder=decoder)"
   ],
   "id": "8a0cd43d660e2ae5",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'LitAutoEncoder' has no attribute 'load_'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 8\u001B[0m\n\u001B[0;32m      3\u001B[0m         \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[0;32m      5\u001B[0m     \u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m----> 8\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mLitAutoEncoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_\u001B[49m\u001B[38;5;241m/\u001B[39mfrom_checkpoint(PATH, encoder\u001B[38;5;241m=\u001B[39mencoder, decoder\u001B[38;5;241m=\u001B[39mdecoder)\n",
      "\u001B[1;31mAttributeError\u001B[0m: type object 'LitAutoEncoder' has no attribute 'load_'"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# nn.Module from checkpoint",
   "id": "ae49af3c05b43976"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T04:21:40.857124Z",
     "start_time": "2024-06-10T04:21:40.847187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint = torch.load(\"ckpts/lightning_logs/version_0/checkpoints/epoch=2-step=2250.ckpt\")\n",
    "print(checkpoint.keys())"
   ],
   "id": "f73d3f10e073a8e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers'])\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T04:22:16.247549Z",
     "start_time": "2024-06-10T04:22:16.243355Z"
    }
   },
   "cell_type": "code",
   "source": "autoencoder = LitAutoEncoder(Encoder(), Decoder())",
   "id": "a282b981072177c0",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T04:22:35.227653Z",
     "start_time": "2024-06-10T04:22:35.218050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint = torch.load(\"ckpts/lightning_logs/version_0/checkpoints/epoch=2-step=2250.ckpt\")\n",
    "encoder_weights = {k: v for k, v in checkpoint[\"state_dict\"].items() if k.startswith(\"encoder.\")}\n",
    "decoder_weights = {k: v for k, v in checkpoint[\"state_dict\"].items() if k.startswith(\"decoder.\")}"
   ],
   "id": "9fac4acec4d2c90e",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# EarlyStopping Callback\n",
    "To enable it:\n",
    "\n",
    "- Import EarlyStopping callback.\n",
    "- Log the metric you want to monitor using log() method.\n",
    "- Init the callback, and set monitor to the logged metric of your choice.\n",
    "- Set the mode based on the metric needs to be monitored.\n",
    "- Pass the EarlyStopping callback to the Trainer callbacks flag."
   ],
   "id": "1db95523fa972835"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-10T07:18:56.642409Z",
     "start_time": "2024-06-10T07:14:03.409066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "model = LitAutoEncoder.load_from_checkpoint(\"ckpts/lightning_logs/version_0/checkpoints/epoch=2-step=2250.ckpt\",encoder=Encoder(), decoder=Decoder())\n",
    "\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0.00,\n",
    "    patience=3,\n",
    "    verbose=False,\n",
    "    mode=\"min\")\n",
    "trainer = L.Trainer(callbacks=early_stop_callback)\n",
    "trainer.fit(model, train_loader, valid_loader)\n",
    "\n"
   ],
   "id": "32f4913c4881d242",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | encoder | Encoder | 50.4 K\n",
      "1 | decoder | Decoder | 51.2 K\n",
      "------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cad12852839747f39c72adf224f211bc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training: |                                                                                                   …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc49521d51e1408eb54bb99e3e920de6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fdf32e885ddd40cea70d93eb82e43f30"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a159e72bad2748cc9ad3e3f47b1941c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a94e6d1ba3e34d38b85e6d2f63590411"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ae44d1faa6642caac5227a5ab2f2dd5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b971ed19fae942edbd83030796983d01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2cdae337506432f8ba55c174dac753e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a06910f07b304b58bbd9aaf78b1809c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42d3c1dc7de74ec784ff130540aeae94"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0cca14a17d4943a7b45a3d781ef74c08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dab06a38fdd844b984ffe51ef4951739"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23dccbf0ffe845cdbbf4b496d40f9baf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc31f38e317b49d2b68f3ba822201cba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8409acc5bb9841e38fa8949db93ca99e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f6420de35b648da8e27193be5f90401"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ec1f73333704add961680180441c2d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb686aa3b81c41ed8964b88073d98ed9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be09fc65cd3342d7a369a6a800856b60"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5fa54e130ff149048720fc000c03d27e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58c7fcf16bd041a69959a5545cf62294"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f38a0faf0d8406f81c892f5fd25831d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb666a259f6a4e8ca1a822f2e49bafa5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e51585a676244d9cbd5d89100a5b5da1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a028d134dbf1447eafc84adb65efeef9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e101f15e8e194e5ea8bfa9dd5e8297cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "223c94a73e3d4cf08062c216eeaafa42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1551b36a2fe400280a161cdf8b653ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d00f1765ecaa4b91992e5f5273d2b073"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9036b262bb234da09f8939b6376bb2e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a0c7ff4b1b74f45979d40947c8ef103"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68f4b758d7724eb6b2061577c52d5fe4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a774338f24794190b73ca4842df6707c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6ef43bdb2f446a2a96424ea6197856c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c3d2a3ca5a34b1fa2f05a5dc7139905"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "971307594d1241928d21f70fa93ff7e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "072d51d279844d7facf9a435ea1b4dd2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0fb2eb22ddae40b6af7253e3b0f521d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Validation: |                                                                                                 …"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c687c4124aa043d58510e694209bd8eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Additional parameters that stop training at extreme points:\n",
    "- **stopping_threshold**: Stops training immediately once the monitored quantity reaches this threshold. It is useful when we know that going beyond a certain optimal value does not further benefit us.\n",
    "- **divergence_threshold**: Stops training as soon as the monitored quantity becomes worse than this threshold. When reaching a value this bad, we believes the model cannot recover anymore and it is better to stop early and run with different initial conditions.\n",
    "- **check_finite**: When turned on, it stops training if the monitored metric becomes NaN or infinite.\n",
    "- **check_on_train_epoch_end**: When turned on, it checks the metric at the end of a training epoch. Use this only when you are monitoring any metric logged within training-specific hooks on epoch-level.\n",
    "> - **stopping_threshold**: 一旦监控的量达到这个阈值，立即停止训练。当我们知道超过某个最优值不会再带来任何好处时，这非常有用。\n",
    "> - **divergence_threshold**: 一旦监控的量变得比这个阈值更糟糕，就停止训练。当达到这样糟糕的值时，我们认为模型无法再恢复，最好提前停止并用不同的初始条件重新运行。\n",
    "> - **check_finite**: 打开时，如果监控的指标变为 NaN 或无穷大，则停止训练。\n",
    "> - **check_on_train_epoch_end**: 打开时，它会在每个训练 epoch 结束时检查指标。仅当您监控在 epoch 级别的训练特定钩子中记录的任何指标时，才使用此选项。\n",
    "\n",
    "In case you need early stopping in a different part of training, subclass EarlyStopping and change where it is called:\n",
    "如果你需要在训练的不同部分提前停止，子类 EarlyStops 可以改变它的名称:"
   ],
   "id": "b731c17138954e10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MyEarlyStopping(EarlyStopping):\n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        # override this to disable early stopping at the end of val loop\n",
    "        pass\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        # instead, do it at the end of training loop\n",
    "        self._run_early_stopping_check(trainer)"
   ],
   "id": "3f5dbb99dc0a58b5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vp",
   "language": "python",
   "name": "vp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
